{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd855393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d1a44b",
   "metadata": {},
   "source": [
    "## 6.1 Data Exploration: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acd2f4d",
   "metadata": {},
   "source": [
    "- I strongly encourage you to first explore the data a bit. At the very least, answer the following questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59c0eaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = pickle.load(open('cosmic.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80656337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6755, 18703), (6755,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345500bf",
   "metadata": {},
   "source": [
    "### (a) How many of the 6,755 samples belong to each of the six types of cancer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c828fd4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 608, 2: 1867, 3: 1399, 4: 1363, 5: 1006, 6: 512}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_per_cancer = {i: (y == i).sum() for i in range(1, 7)}\n",
    "samples_per_cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0f8efe",
   "metadata": {},
   "source": [
    "### (b) Count the total number of mutations for each **sample** (i.e. each row of X). What’s the smallest number? The largest number? The average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e41ea036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutation per sample: [ 189  950   80 ... 1560   87   66]\n",
      "Minimum mutation per sample: 45\n",
      "Maximum mutation per sample: 5938\n",
      "Average mutation per sample: 241.75292376017765\n"
     ]
    }
   ],
   "source": [
    "# number of mutations in each samples \n",
    "mutations_per_sample = np.sum(X, axis=1)\n",
    "min_mutations_sample = np.min(mutations_per_sample)\n",
    "max_mutations_sample = np.max(mutations_per_sample)\n",
    "average_mutations_sample = np.mean(mutations_per_sample)\n",
    "\n",
    "print(f\"Mutation per sample: {mutations_per_sample}\")\n",
    "print(f\"Minimum mutation per sample: {min_mutations_sample}\")\n",
    "print(f\"Maximum mutation per sample: {max_mutations_sample}\")\n",
    "print(f\"Average mutation per sample: {average_mutations_sample}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ece7532",
   "metadata": {},
   "source": [
    "This shows the number of mutations in DNA of each cancer patients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0776734d",
   "metadata": {},
   "source": [
    "### (c) Count the total number of mutations for each **gene** (i.e. each column of X). What’s the smallest number? The largest number? The average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "697c018c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutation per gene: [ 84  78  56 ... 120 102  35]\n",
      "Minimum mutation per gene: 30\n",
      "Maximum mutation per gene: 1768\n",
      "Average mutation per gene: 87.31438806608566\n"
     ]
    }
   ],
   "source": [
    "# number of mutations in each gene\n",
    "mutations_per_gene = np.sum(X, axis=0)\n",
    "min_mutations_gene = np.min(mutations_per_gene)\n",
    "max_mutations_gene = np.max(mutations_per_gene)\n",
    "average_mutations_gene = np.mean(mutations_per_gene)\n",
    "\n",
    "print(f\"Mutation per gene: {mutations_per_gene}\")\n",
    "print(f\"Minimum mutation per gene: {min_mutations_gene}\")\n",
    "print(f\"Maximum mutation per gene: {max_mutations_gene}\")\n",
    "print(f\"Average mutation per gene: {average_mutations_gene}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4413fd58",
   "metadata": {},
   "source": [
    "This shows the number of mutations in each genes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc8b3b7",
   "metadata": {},
   "source": [
    "## 6.2 Baseline (No PCA): "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07be1ecd",
   "metadata": {},
   "source": [
    "- Let’s get a sense of how well we can predict the type of cancer from mutations. Treat the first 4,500 rows of the data as your training set (and the remaining 2,255 rows as your test set). Now there are 6 types of cancer here: for each type of cancer, you will build a separate binary classifier which aims to distinguish that type of cancer from the other five. \n",
    "- For each of these 6 separate binary classification tasks, at the very least, try each of the following algorithms, and report the out-of-sample AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c48b21f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually splitting the data\n",
    "\n",
    "X_train = X[:4500]\n",
    "X_test = X[4500:]\n",
    "\n",
    "y_train = y[:4500]\n",
    "y_test = y[4500:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d713dea5",
   "metadata": {},
   "source": [
    "### (a) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8f6a6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.9596146404466713,\n",
       " 2: 0.9549911317873117,\n",
       " 3: 0.9248159793489283,\n",
       " 4: 0.9406775286257196,\n",
       " 5: 0.8847479752525764,\n",
       " 6: 0.9151598522076091}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making dictionary to list all type of cancers and corresponding AUC\n",
    "\n",
    "auc_scores_lr = {}\n",
    "\n",
    "for cancer_type in range(1, 7):\n",
    "    y_train_binary = (y_train == cancer_type).astype(int)\n",
    "    y_test_binary = (y_test == cancer_type).astype(int)\n",
    "\n",
    "    model_lr = LogisticRegression(solver='liblinear', random_state=0)\n",
    "    model_lr.fit(X_train, y_train_binary)\n",
    "\n",
    "    y_pred_prob = model_lr.predict_proba(X_test)[:, 1]\n",
    "    auc = roc_auc_score(y_test_binary, y_pred_prob)\n",
    "    auc_scores_lr[cancer_type] = auc\n",
    "\n",
    "auc_scores_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c549fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average AUC for Logistic Regression: 0.9300011846114695\n"
     ]
    }
   ],
   "source": [
    "average_auc_lr = sum(auc_scores_lr.values()) / len(auc_scores_lr)\n",
    "print(\"Average AUC for Logistic Regression:\", average_auc_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddd39be",
   "metadata": {},
   "source": [
    "my Logistic Regression model (binary classifier) distinguishes the type 1 (Kidney Cancer) the best."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846f5953",
   "metadata": {},
   "source": [
    "### (b) Logistic Regression with L1 penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d3948ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.9484943437379073,\n",
       " 2: 0.9437528477033579,\n",
       " 3: 0.8946157280036489,\n",
       " 4: 0.9067789735547023,\n",
       " 5: 0.8858894333158667,\n",
       " 6: 0.9081200998711852}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_scores_lr_l1 = {}\n",
    "\n",
    "for cancer_type in range(1, 7):\n",
    "    y_train_binary = (y_train == cancer_type).astype(int)\n",
    "    y_test_binary = (y_test == cancer_type).astype(int)\n",
    "\n",
    "    model_lr_l1 = LogisticRegression(solver='liblinear', penalty='l1', random_state=0)\n",
    "    model_lr_l1.fit(X_train, y_train_binary)\n",
    "\n",
    "    y_pred_prob = model_lr_l1.predict_proba(X_test)[:, 1]\n",
    "    auc = roc_auc_score(y_test_binary, y_pred_prob)\n",
    "    auc_scores_lr_l1[cancer_type] = auc\n",
    "\n",
    "auc_scores_lr_l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87c65b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average AUC for Logistic Regression: 0.9146085710311115\n"
     ]
    }
   ],
   "source": [
    "average_auc_lr_l1 = sum(auc_scores_lr_l1.values()) / len(auc_scores_lr_l1)\n",
    "print(\"Average AUC for Logistic Regression:\", average_auc_lr_l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d938a24c",
   "metadata": {},
   "source": [
    "my Logistic Regression model with L1 penalty (Lasso) also distinguishes the type 1 (Kidney Cancer) the best."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eafd80",
   "metadata": {},
   "source": [
    "### (c) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54464edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.7763565229190433,\n",
       " 2: 0.8757516470236244,\n",
       " 3: 0.7724858193710545,\n",
       " 4: 0.7864747469284812,\n",
       " 5: 0.7052801245338408,\n",
       " 6: 0.7873947085235073}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_scores_rf = {}\n",
    "\n",
    "for cancer_type in range(1, 7):\n",
    "    y_train_binary = (y_train == cancer_type).astype(int)\n",
    "    y_test_binary = (y_test == cancer_type).astype(int)\n",
    "    \n",
    "    model_rf = RandomForestClassifier(n_estimators=10, random_state=0, n_jobs=-1)\n",
    "    model_rf.fit(X_train, y_train_binary)\n",
    "\n",
    "    y_pred_prob = model_rf.predict_proba(X_test)[:, 1]\n",
    "    auc = roc_auc_score(y_test_binary, y_pred_prob)\n",
    "    auc_scores_rf[cancer_type] = auc\n",
    "\n",
    "auc_scores_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3388c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average AUC for Logistic Regression: 0.7839572615499252\n"
     ]
    }
   ],
   "source": [
    "average_auc_rf = sum(auc_scores_rf.values()) / len(auc_scores_rf)\n",
    "print(\"Average AUC for Logistic Regression:\", average_auc_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239e26aa",
   "metadata": {},
   "source": [
    "my Random Forest model distinguishes the type 2 (Large Intestine) the best."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ede7e2",
   "metadata": {},
   "source": [
    " It is concluded that the Normal Logistic Regression model shows the best performance for classifying most types of cancer, as it achieves the highest average AUC score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2208147a",
   "metadata": {},
   "source": [
    "## 6.3 PCA: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604896cf",
   "metadata": {},
   "source": [
    "- Repeat part 6.2, this time pre-processing the data using PCA. You will need to tune the number of components. I recommend you do this with the simplest possible method for validation: manually split your training set into a “training” and “validation” set (say 3,000 rows for the training set, and 1,500 rows for the validation set). Once again, at the very least, try each of the following algorithms, and report the out-of-sample AUC (so 18 AUCs in total):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64519d74",
   "metadata": {},
   "source": [
    "#### But Why PCA before training the model? and What matters with the different components in PCA?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc9a45c",
   "metadata": {},
   "source": [
    "PCA is a powerful tool for pre-processing and feature engineering in machine learning. It helps to make the data more manageable for models, potentially improving performance, reducing overfitting, and saving computational resources. Testing different numbers of components is crucial to leverage the benefits of PCA fully, as it helps in identifying the sweet spot where the reduced feature set captures the essence of the original data without including too much noise or losing significant information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3c5f6c",
   "metadata": {},
   "source": [
    "### (a) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be72b75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Components: 20, AUC Scores: {1: 0.8168370217554388, 2: 0.7257229311695679, 3: 0.6800764781126023, 4: 0.8130503755503755, 5: 0.6234462391475035, 6: 0.7788}\n",
      "Average AUC: 0.7396555076225813\n",
      "\n",
      "PCA Components: 50, AUC Scores: {1: 0.8432166635408852, 2: 0.8058577462378761, 3: 0.713915609052975, 4: 0.8889806181472848, 5: 0.6726819196681001, 6: 0.8006357142857142}\n",
      "Average AUC: 0.7875480451554725\n",
      "\n",
      "PCA Components: 100, AUC Scores: {1: 0.8667010502625657, 2: 0.8432313289685792, 3: 0.7464458500888368, 4: 0.8916542562375898, 5: 0.6964919819962455, 6: 0.8371857142857143}\n",
      "Average AUC: 0.8136183636399218\n",
      "\n",
      "PCA Components: 1000, AUC Scores: {1: 0.9284684452363091, 2: 0.9448964796786773, 3: 0.8747035391409463, 4: 0.9133644133644134, 5: 0.817681289601313, 6: 0.9242142857142857}\n",
      "Average AUC: 0.9005547421226575\n",
      "\n",
      "PCA Components: 3000, AUC Scores: {1: 0.9418663259564891, 2: 0.9546834052286993, 3: 0.8907509620611231, 4: 0.9160407493740828, 5: 0.8553528212452058, 6: 0.9106857142857143}\n",
      "Average AUC: 0.9115633296918858\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Manually splitted the original training set in to training and validation\n",
    "\n",
    "X_new_train = X_train[:3000, :]\n",
    "X_validation = X_train[3000:4500, :]\n",
    "y_new_train = y_train[:3000]\n",
    "y_validation = y_train[3000:4500]\n",
    "\n",
    "pca_components_list = [20, 50, 100, 1000, 3000]\n",
    "\n",
    "auc_scores = {n_components: {} for n_components in pca_components_list}\n",
    "\n",
    "for n_components in pca_components_list:\n",
    "    \n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_new_train_pca = pca.fit_transform(X_new_train)\n",
    "    X_validation_pca = pca.transform(X_validation)\n",
    "    \n",
    "    for cancer_type in range(1, 7):\n",
    "        y_new_train_binary = (y_new_train == cancer_type).astype(int)\n",
    "        y_validation_binary = (y_validation == cancer_type).astype(int)\n",
    "        \n",
    "        model = LogisticRegression(solver='liblinear', random_state=0)\n",
    "        model.fit(X_new_train_pca, y_new_train_binary)\n",
    "        \n",
    "        y_pred_prob = model.predict_proba(X_validation_pca)[:, 1]\n",
    "        auc = roc_auc_score(y_validation_binary, y_pred_prob)\n",
    "        \n",
    "        auc_scores[n_components][cancer_type] = auc\n",
    "\n",
    "for n_components, scores in auc_scores.items():\n",
    "    average_auc = sum(scores.values()) / len(scores)\n",
    "    print(f\"PCA Components: {n_components}, AUC Scores: {scores}\")\n",
    "    print(f\"Average AUC: {average_auc}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fb65f8",
   "metadata": {},
   "source": [
    "### (b) Logistic Regression with L1 penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fc2f785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Components: 20, AUC Scores: {1: 0.8147388409602401, 2: 0.7297619798092596, 3: 0.6806795410231518, 4: 0.81285882327549, 5: 0.6236401058512203, 6: 0.7771857142857143}\n",
      "Average AUC: 0.7398108342008459\n",
      "\n",
      "PCA Components: 50, AUC Scores: {1: 0.8401162790697675, 2: 0.8001031150656064, 3: 0.7086124414853197, 4: 0.8902945048778382, 5: 0.6730728841872622, 6: 0.7917500000000001}\n",
      "Average AUC: 0.7839915374476324\n",
      "\n",
      "PCA Components: 100, AUC Scores: {1: 0.8705985090022507, 2: 0.8384538143568592, 3: 0.7511189115660977, 4: 0.8932433307433308, 5: 0.6992028847365515, 6: 0.8371857142857142}\n",
      "Average AUC: 0.814967194115134\n",
      "\n",
      "PCA Components: 1000, AUC Scores: {1: 0.9174207614403601, 2: 0.9449347538296666, 3: 0.8802690255531007, 4: 0.9074640637140636, 5: 0.8197815122249112, 6: 0.9183214285714285}\n",
      "Average AUC: 0.8980319242222552\n",
      "\n",
      "PCA Components: 3000, AUC Scores: {1: 0.9206911102775693, 2: 0.9543141722426852, 3: 0.8761828010784819, 4: 0.9152070922904256, 5: 0.8477273975656805, 6: 0.9221714285714286}\n",
      "Average AUC: 0.9060490003377119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pca_components_list = [20, 50, 100, 1000, 3000]\n",
    "\n",
    "auc_scores_lr_l1 = {n_components: {} for n_components in pca_components_list}\n",
    "\n",
    "for n_components in pca_components_list:\n",
    "    pca_l1 = PCA(n_components=n_components)\n",
    "    X_new_train_pca_l1 = pca_l1.fit_transform(X_new_train)\n",
    "    X_validation_pca_l1 = pca_l1.transform(X_validation)\n",
    "    \n",
    "    for cancer_type in range(1, 7):\n",
    "        y_new_train_binary_l1 = (y_new_train == cancer_type).astype(int)\n",
    "        y_validation_binary_l1 = (y_validation == cancer_type).astype(int)\n",
    "        \n",
    "        model_lr_l1 = LogisticRegression(solver='liblinear', penalty='l1', random_state=0)\n",
    "        model_lr_l1.fit(X_new_train_pca_l1, y_new_train_binary_l1)\n",
    "        \n",
    "        y_pred_prob_l1 = model_lr_l1.predict_proba(X_validation_pca_l1)[:, 1]\n",
    "        auc_l1 = roc_auc_score(y_validation_binary_l1, y_pred_prob_l1)\n",
    "        \n",
    "        auc_scores_lr_l1[n_components][cancer_type] = auc_l1\n",
    "\n",
    "for n_components, scores in auc_scores_lr_l1.items():\n",
    "    average_auc = sum(scores.values()) / len(scores)\n",
    "    print(f\"PCA Components: {n_components}, AUC Scores: {scores}\")\n",
    "    print(f\"Average AUC: {average_auc}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585cbc01",
   "metadata": {},
   "source": [
    "### (c) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9f82803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Components: 20, AUC Scores: {1: 0.7245815360090022, 2: 0.7563523833538963, 3: 0.6627972383504742, 4: 0.8465423465423465, 5: 0.6448055032294961, 6: 0.6693357142857143}\n",
      "Average AUC: 0.7174024536284883\n",
      "\n",
      "PCA Components: 50, AUC Scores: {1: 0.7304482370592649, 2: 0.7700230095190066, 3: 0.6562771276897823, 4: 0.8570628831045497, 5: 0.6609917574339803, 6: 0.7443535714285714}\n",
      "Average AUC: 0.7365260977058593\n",
      "\n",
      "PCA Components: 100, AUC Scores: {1: 0.718978572768192, 2: 0.7773738979295937, 3: 0.6677921136678935, 4: 0.8647492553742554, 5: 0.6512822666894998, 6: 0.7033071428571429}\n",
      "Average AUC: 0.7305805415477629\n",
      "\n",
      "PCA Components: 1000, AUC Scores: {1: 0.7852031367216803, 2: 0.7789251267549824, 3: 0.6837908588643486, 4: 0.8213559203142538, 5: 0.6558413653385721, 6: 0.830867857142857}\n",
      "Average AUC: 0.7593307108561157\n",
      "\n",
      "PCA Components: 3000, AUC Scores: {1: 0.4375175825206301, 2: 0.6737691483325978, 3: 0.5210152550577508, 4: 0.7990373823707158, 5: 0.4984393730350801, 6: 0.43273571428571433}\n",
      "Average AUC: 0.5604190759337481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pca_components_list = [20, 50, 100, 1000, 3000]\n",
    "\n",
    "auc_scores_rf_pca = {n_components: {} for n_components in pca_components_list}\n",
    "\n",
    "for n_components in pca_components_list:\n",
    "    pca_rf = PCA(n_components=n_components)\n",
    "    X_new_train_pca_rf = pca_rf.fit_transform(X_new_train)\n",
    "    X_validation_pca_rf = pca_rf.transform(X_validation)\n",
    "    \n",
    "    for cancer_type in range(1, 7):\n",
    "        y_new_train_binary_rf = (y_new_train == cancer_type).astype(int)\n",
    "        y_validation_binary_rf = (y_validation == cancer_type).astype(int)\n",
    "        \n",
    "        model_rf_pca = RandomForestClassifier(n_estimators=10, random_state=0, n_jobs=-1)\n",
    "        model_rf_pca.fit(X_new_train_pca_rf, y_new_train_binary_rf)\n",
    "        \n",
    "        y_pred_prob_rf = model_rf_pca.predict_proba(X_validation_pca_rf)[:, 1]\n",
    "        auc_rf = roc_auc_score(y_validation_binary_rf, y_pred_prob_rf)\n",
    "        \n",
    "        auc_scores_rf_pca[n_components][cancer_type] = auc_rf\n",
    "\n",
    "for n_components, scores in auc_scores_rf_pca.items():\n",
    "    average_auc = sum(scores.values()) / len(scores)\n",
    "    print(f\"PCA Components: {n_components}, AUC Scores: {scores}\")\n",
    "    print(f\"Average AUC: {average_auc}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2174586",
   "metadata": {},
   "source": [
    "## 6.4 Summary: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cc3d6b",
   "metadata": {},
   "source": [
    "- What is your final proposed procedure for achieving the highest out-of-sample AUC averaged across all six types of cancer? What is your proposed procedure’s average out-of-sample AUC?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02b08cf",
   "metadata": {},
   "source": [
    "After calculating the average AUC values for each algorithm (Logistic Regression, Logistic Regression with L1 regularization, and Random Forest) with and without PCA, I concluded that the baseline Logistic Regression model performs the best in classifying the Cancer Type based on the gene mutation status. The AUC values for each type of cancer were {1: 0.9596146404466713, 2: 0.9549911317873117, 3: 0.9248159793489283, 4: 0.9406775286257196, 5: 0.8847479752525764, 6: 0.9151598522076091}, and the average AUC was 0.9300011846114695. This means that the model is able to discriminate between positive and negative cases of cancer with about 93% accuracy for each type of cancer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
